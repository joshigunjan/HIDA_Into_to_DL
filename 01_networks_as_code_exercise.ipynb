{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maleehahassan/HIDA_Into_to_DL/blob/main/01_networks_as_code_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview: Wine Classification with Neural Networks\n",
        "\n",
        "This notebook demonstrates how to classify wine samples into three categories using a neural network and the classic sklearn wine dataset. The workflow includes:\n",
        "\n",
        "1. **Data Loading & Exploration**: The wine dataset is loaded and its features are inspected.\n",
        "2. **Preprocessing**: The target labels are one-hot encoded for multiclass classification. Features are normalized using standard scaling to improve model performance.\n",
        "3. **Data Splitting**: The data is split into training and test sets, stratified by class to ensure balanced representation.\n",
        "4. **Model Building**: A simple feedforward neural network is constructed using TensorFlow/Keras, with one hidden layer and a softmax output for multiclass classification.\n",
        "5. **Training**: The model is trained for 18 epochs, and training loss is visualized to monitor learning progress.\n",
        "6. **Prediction & Evaluation**: Predictions are made on the test set, and the modelâ€™s performance is evaluated using a confusion matrix and accuracy score.\n",
        "\n",
        "This notebook helps learners understand the full workflow of preparing data, building and training a neural network for multiclass classification, and evaluating results using visual tools."
      ],
      "metadata": {
        "id": "PtlIJPTvdz-5"
      },
      "id": "PtlIJPTvdz-5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "248ee82b",
      "metadata": {
        "id": "248ee82b"
      },
      "outputs": [],
      "source": [
        "# Import the wine dataset from sklearn\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "# Load the dataset into a variable\n",
        "dataset = load_wine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55770dc7",
      "metadata": {
        "collapsed": true,
        "id": "55770dc7",
        "outputId": "a28e258c-8dff-4174-e1ce-dd384c81b3ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
              "         1.065e+03],\n",
              "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
              "         1.050e+03],\n",
              "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
              "         1.185e+03],\n",
              "        ...,\n",
              "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
              "         8.350e+02],\n",
              "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
              "         8.400e+02],\n",
              "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
              "         5.600e+02]]),\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2]),\n",
              " 'frame': None,\n",
              " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
              " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
              " 'feature_names': ['alcohol',\n",
              "  'malic_acid',\n",
              "  'ash',\n",
              "  'alcalinity_of_ash',\n",
              "  'magnesium',\n",
              "  'total_phenols',\n",
              "  'flavanoids',\n",
              "  'nonflavanoid_phenols',\n",
              "  'proanthocyanins',\n",
              "  'color_intensity',\n",
              "  'hue',\n",
              "  'od280/od315_of_diluted_wines',\n",
              "  'proline']}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the dataset dictionary to inspect its contents\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b10edc28",
      "metadata": {
        "collapsed": true,
        "id": "b10edc28",
        "outputId": "cb651d99-e51c-4b6d-f118-226f0d0e0e04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['alcohol',\n",
              " 'malic_acid',\n",
              " 'ash',\n",
              " 'alcalinity_of_ash',\n",
              " 'magnesium',\n",
              " 'total_phenols',\n",
              " 'flavanoids',\n",
              " 'nonflavanoid_phenols',\n",
              " 'proanthocyanins',\n",
              " 'color_intensity',\n",
              " 'hue',\n",
              " 'od280/od315_of_diluted_wines',\n",
              " 'proline']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show the feature names in the dataset\n",
        "dataset['feature_names']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4adcd6cb",
      "metadata": {
        "id": "4adcd6cb"
      },
      "outputs": [],
      "source": [
        "# Import pandas for data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "X = dataset['data']\n",
        "\n",
        "# Assign the feature data to X and one-hot encode the target labels\n",
        "y = pd.get_dummies(dataset[\"target\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "219216af",
      "metadata": {
        "collapsed": true,
        "id": "219216af",
        "outputId": "06bb54e8-723f-4f0d-a824-e0bb7801559c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> (178, 13)\n"
          ]
        }
      ],
      "source": [
        "# Print the type and shape of the feature matrix X\n",
        "print(type(X), X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69986241",
      "metadata": {
        "collapsed": true,
        "id": "69986241",
        "outputId": "9330e027-3470-4cfd-cf6d-1768e82ac601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'> (178, 3)\n"
          ]
        }
      ],
      "source": [
        "# Print the type and shape of the one-hot encoded target y\n",
        "print(type(y), y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f65c786a",
      "metadata": {
        "id": "f65c786a"
      },
      "outputs": [],
      "source": [
        "# Import StandardScaler for feature normalization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Fit the scaler to X and transform X to have zero mean and unit variance\n",
        "scaler = StandardScaler().fit(X)\n",
        "X_ = scaler.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fd83aeb",
      "metadata": {
        "collapsed": true,
        "id": "4fd83aeb",
        "outputId": "23687ede-2e09-4ea7-9c6e-f4d1c216398a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean values per column:\n",
            " [ 7.84141790e-15  2.44498554e-16 -4.05917497e-15 -7.11041712e-17\n",
            " -2.49488320e-17 -1.95536471e-16  9.44313292e-16 -4.17892936e-16\n",
            " -1.54059038e-15 -4.12903170e-16  1.39838203e-15  2.12688793e-15\n",
            " -6.98567296e-17]\n"
          ]
        }
      ],
      "source": [
        "# Print the mean values per column after scaling\n",
        "print(\"mean values per column:\\n\", X_.mean(axis=-2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "342440b8",
      "metadata": {
        "collapsed": true,
        "id": "342440b8",
        "outputId": "c112cf58-85f4-4758-c961-f39cae6e4b82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "std  values per column:\n",
            " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "# Print the standard deviation values per column after scaling\n",
        "print(\"std  values per column:\\n\", X_.std(axis=-2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "306fd652",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "collapsed": true,
        "id": "306fd652",
        "outputId": "8c0b023d-0c40-42f9-f236-5cf44ddaa92e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3589698574.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m X_train, X_test, y_train, y_test = train_test_split(X_, y ,test_size=0.2, \n\u001b[0m\u001b[1;32m      4\u001b[0m                                                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_' is not defined"
          ]
        }
      ],
      "source": [
        "# Import train_test_split to split data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_, y ,test_size=0.2,\n",
        "                                                    random_state=0,\n",
        "                                                    shuffle=True,\n",
        "                                                    stratify=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3dc7308",
      "metadata": {
        "collapsed": true,
        "id": "f3dc7308",
        "outputId": "b27f4434-a61d-4d60-d95d-118f3c0f7964"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(142, 13) (36, 13) (142, 3) (36, 3)\n"
          ]
        }
      ],
      "source": [
        "# Print the shapes of the train and test splits for features and targets\n",
        "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3656721a",
      "metadata": {
        "collapsed": true,
        "id": "3656721a",
        "outputId": "c7271df1-e560-4be9-ef50-64f6011b0f4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-25 09:20:42.252327: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-03-25 09:20:42.252351: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "source": [
        "# Set random seeds for reproducibility\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow.random import set_seed\n",
        "set_seed(2)\n",
        "from tensorflow import keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c214ff85",
      "metadata": {
        "id": "c214ff85"
      },
      "outputs": [],
      "source": [
        "# Define a function to create the neural network model\n",
        "def create_model(X_shape):\n",
        "    # Input layer\n",
        "    inputs = keras.Input(shape=X_shape[1])\n",
        "\n",
        "    # Hidden layer with 16 units and ReLU activation\n",
        "    hidden_layer = keras.layers.Dense(16, activation=\"relu\")(inputs)\n",
        "    #hidden_layer = keras.layers.Dense(32, activation=\"relu\")(hidden_layer)\n",
        "\n",
        "    # Output layer with 3 units (for 3 classes) and softmax activation\n",
        "    output_layer = keras.layers.Dense(3, activation=\"softmax\")(hidden_layer)\n",
        "\n",
        "    # Create the model object\n",
        "    model = keras.Model(inputs=inputs, outputs=output_layer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0688045d",
      "metadata": {
        "collapsed": true,
        "id": "0688045d",
        "outputId": "856a78f4-b88f-4875-e4b5-19dc40f9aca9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-25 09:20:44.124295: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
            "2022-03-25 09:20:44.124323: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2022-03-25 09:20:44.124339: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fwc049): /proc/driver/nvidia/version does not exist\n",
            "2022-03-25 09:20:44.124505: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# Create the model using the training data shape\n",
        "model = create_model(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5daf2e28",
      "metadata": {
        "collapsed": true,
        "id": "5daf2e28",
        "outputId": "1d0ebf0a-aebe-41e9-e994-c0a532a0a6c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 13)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                224       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 275\n",
            "Trainable params: 275\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Display the model architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64122c8d",
      "metadata": {
        "id": "64122c8d"
      },
      "outputs": [],
      "source": [
        "# Compile the model with Adam optimizer and categorical crossentropy loss\n",
        "model.compile(optimizer='adam', loss=keras.losses.CategoricalCrossentropy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83408f6b",
      "metadata": {
        "collapsed": true,
        "id": "83408f6b",
        "outputId": "495d6069-28a0-4164-cdbc-9d6f7dec31db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/18\n",
            "5/5 [==============================] - 0s 899us/step - loss: 1.2224\n",
            "Epoch 2/18\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 1.1295\n",
            "Epoch 3/18\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 1.0460\n",
            "Epoch 4/18\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.9641\n",
            "Epoch 5/18\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.8902\n",
            "Epoch 6/18\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.8227\n",
            "Epoch 7/18\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.7612\n",
            "Epoch 8/18\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.7060\n",
            "Epoch 9/18\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6541\n",
            "Epoch 10/18\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.6091\n",
            "Epoch 11/18\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 0.5668\n",
            "Epoch 12/18\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.5293\n",
            "Epoch 13/18\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.4948\n",
            "Epoch 14/18\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4638\n",
            "Epoch 15/18\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4351\n",
            "Epoch 16/18\n",
            "5/5 [==============================] - 0s 2ms/step - loss: 0.4092\n",
            "Epoch 17/18\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3856\n",
            "Epoch 18/18\n",
            "5/5 [==============================] - 0s 3ms/step - loss: 0.3641\n"
          ]
        }
      ],
      "source": [
        "# Train the model on the training data for 18 epochs\n",
        "history = model.fit(X_train, y_train, epochs=18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "725cf7e9",
      "metadata": {
        "collapsed": true,
        "id": "725cf7e9",
        "outputId": "ac11c408-c76f-44e0-9f81-ab5e1f1b0af8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD4CAYAAAAJmJb0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAhmElEQVR4nO3dd3iUVf7+8fcnlRIIJQktQJCAdBVCFxCxALpiwwUUUSmylq+uq/t1y8+vu27VXVddRVYEFazYsaKsFOkEpNfQJJQQeift/P7I4GYjgUAm88xM7td1cZGZOcnc15Px9nDmmfOYcw4REQlPEV4HEBGR8qOSFxEJYyp5EZEwppIXEQljKnkRkTAW5dUTJyQkuJSUFK+eXkQkJC1evHiPcy6xtOM9K/mUlBTS09O9enoRkZBkZlvPZbyWa0REwphKXkQkjKnkRUTCmEpeRCSMqeRFRMKYSl5EJIyp5EVEwljIlXz24ZP87pNV5OQVeB1FRCTohVzJp2/ZxytztvDbj1agvfBFRM4s5Eq+X9t6/M/lqUxOz2T87M1exxERCWpnLXkzm2Bmu81sZQmP32pmy81shZnNNbOL/B/zvz14RXP6t63LHz9fw7/XZJX304mIhKzSzORfBfqe4fHNQC/nXFvgCeAlP+Q6o4gI4+8DL6ZN/Xj+563vWLvrUHk/pYhISDpryTvnZgH7zvD4XOfcft/N+UCyn7KdUeWYSMbdnkZcpSiGv5rOniMnA/G0IiIhxd9r8sOBL0p60MxGmVm6maVnZ2eX+cnqxldi3O1p7D16krsnLeZkXn6Zf6aISDjxW8mbWW8KS/5/SxrjnHvJOZfmnEtLTCz1dshn1C65Bn8feDGLt+7nVx/ojBsRkaL8UvJm1g54GRjgnNvrj595Lq5pV4+HrmzOB0u28+LMjYF+ehGRoFXmi4aYWSPgA2Coc2592SOdn/svT2XD7iM8+eU6LkiIo2+bul5FEREJGmcteTN7C7gMSDCzTOD/gGgA59xY4DGgNjDGzADynHNp5RX4DDl56uZ2bNt3jJ+/s5Tkml1p0yA+0DFERIKKebWGnZaW5srj8n+7D5/g+ufn4ICP7+1OUvVKfn8OERGvmNnic5lIh9wnXs8mqVolxg1L48CxXEZOWsyJXJ1xIyIVV9iVPEDr+vE8M+hilm07wCPvLdcZNyJSYYVlyQNc3bouv+x7IZ8s28E/v8nwOo6IiCfKfHZNMPtZr6Zk7D7C01+v54LEqlzbrr7XkUREAipsZ/JQeMbNn29sS1rjmvxi8jKWbTvgdSQRkYAK65IHiI2KZOzQDiTExTJyYjq7Dp7wOpKISMCEfckDJMTFMv6ONI6ezGPExEUcz9EZNyJSMVSIkgdoUbc6zw2+hFU7DvHQ5KUUFOiMGxEJfxWm5AH6tKzDr/u15IuVu/jHNM92YBARCZiwPrvmdEb0aELG7iP885sMUpPiGHBxA68jiYiUmwpX8mbGE9e3YfPeozzy3nISq8XSrWmC17FERMpFhVquOSUmKoJ/3daBxrWqMPK1dJZnHvA6kohIuaiQJQ9Qs2oMk4Z3pmbVGIZNWMiGrMNeRxIR8bsKW/JQePnA14d3JjIigqHjF7Jt3zGvI4mI+FWFLnmAlISqTBreiWM5eQwdv4Dsw7oguIiEjwpf8gAt61XnlTs7knXoJLdPWMjB47leRxIR8QuVvE+HxrUYO7QDGbsPM/xVfSpWRMKDSr6IXs0TeXbQJSz5fj+jX19MTl6B15FERMpEJV9M/7b1+NMNbZm5PpuHJi8lX9sfiEgIq3AfhiqNQZ0acfB4Ln/+Yi3VKkXzpxva4LtIuYhISFHJl+DuXk05cDyXF2dspEaVaP63bwuvI4mInDOV/Bn88uoLOegr+vjK0Yzu1dTrSCIi50QlfwZmxhMD2nDoeC5/+WIt8ZWjGdypkdexRERKTSV/FpERxtO3XMyRk3n8+sMVVK8UzTXt6nkdS0SkVHR2TSnEREXw4q0d6NCoJg++8x0z12d7HUlEpFRU8qVUOSaS8Xd0JDWpGqMnLWbx1n1eRxIROSuV/DmIrxzNxLs6Uad6LHe+sog1Ow95HUlE5IxU8ucosVosr4/oTJWYKIaOX8iWPUe9jiQiUiKV/HlIrlmF10d0Ir+ggNvGL2DXwRNeRxIROS2V/HlKTarGa3d1Yv/RHIaOX8C+ozleRxIR+RGVfBm0S67By8M68v2+Y9w+YQGHTmiLYhEJLir5MuratDZjb+vA2p2HueuVRRzLyfM6kojID1TyftC7RdIPWxTfPWkxJ3K1F72IBAeVvJ9c064ef72pHd9u2MP9b31Hbr72ohcR76nk/WhgWkN+d11rvl6dxcPvLtNe9CLiOe1d42fDuqVw5GQeT01dR5WYSP50Q1vtRS8inlHJl4N7e6dy9GQeY2ZspGpMFL+5pqWKXkQ8cdblGjObYGa7zWxlCY+bmT1nZhlmttzM2vs/Zuh55OoLuaNbCi/P3swz0zZ4HUdEKqjSrMm/CvQ9w+P9gGa+P6OAF8seK/SZGY9d24qbOyTz7L83MG7WJq8jiUgFdNblGufcLDNLOcOQAcBE55wD5ptZDTOr55zb6a+QoSoiwvjrTe04npPPHz9fQ5XYSG7t3NjrWCJSgfhjTb4BsK3I7UzffT8qeTMbReFsn0aNKsYVliIjjH/89GKO5+bz249WUiUmkhsuSfY6lohUEAE9hdI595JzLs05l5aYmBjIp/ZUTFQEY25tT5cmtXn43eV8uXKX15FEpILwR8lvBxoWuZ3su0+KqBQdybhhabRtEM//vPUds3R1KREJAH+U/BTgdt9ZNl2Ag1qPP7242Cheu7MTTZPiGDUpnYWbdXUpESlfpTmF8i1gHnChmWWa2XAzG21mo31DPgc2ARnAOOCecksbBuKrRDNpeCfq16jMXa8uYnnmAa8jiUgYs8KTYgIvLS3Npaene/LcwWDnweMMHDuPIyfzeGdUVy6sW83rSCISAsxssXMurbTjtXeNR+rFV+aNEZ2JiYzgtvEL2KzLCIpIOVDJe6hx7aq8MaIz+QWO215ewPYDx72OJCJhRiXvsWZ1qjHxrk4cOp7LkHHzydx/zOtIIhJGVPJBoE2DeF4b3ol9R3O4Zew8Ld2IiN+o5INE+0Y1eWtkF07kFTBw7DzW7jrkdSQRCQMq+SDSpkE8k+/uQmQEDHppvk6vFJEyU8kHmdSkarx7dzfiYqMYMm6BPjAlImWikg9CjWpX4d3RXUmqHsvtExYwU1sgiMh5UskHqXrxlZl8d1eaJMQx8rV0pq7SpmYicu5U8kEsIS6Wt0d2oVX96tzzxhI++k77vonIuVHJB7n4KtG8PqIzHVNq8vPJS3lzwfdeRxKREKKSDwFxsVG8emcnLmueyK8/XMHL3+pSgiJSOir5EFEpOpJ/DU2jf9u6/OGzNTwzbT1ebS4nIqHDH5f/kwCJiYrguUGXUDl6Bc9M28DRk3n8un9LzMzraCISpFTyISYqMoKnbm5H1dhIxn27mWM5+TwxoA0RESp6EfkxlXwIiogwfndda6rGRvHijI0cy8nnqZvbERWp1TcR+W8q+RBlZvxv3xbExUbx1NR1HMvJ47nBlxAbFel1NBEJIpr6hbh7e6fy2LWtmLoqi5ETF3M8J9/rSCISRFTyYeCuS5vw5E3t+HZDNsMmLOTwiVyvI4lIkFDJh4lbOjbk2UGXsOT7/QweN5/dh054HUlEgoBKPoxcd1F9Xrq9Axt3H+WGMXNZn3XY60gi4jGVfJi5vEUdJt/dlZz8Am56cS5zM/Z4HUlEPKSSD0Ntk+P58J5u1IuvxLBXFvL+4kyvI4mIR1TyYSq5ZhXeHd2Njim1+MW7y3h22gZtgyBSAankw1h85WhevbMTN7VP5h/T1vPwu8vJySvwOpaIBJA+DBXmYqIi+NvAdjSqVYV/TFvPzoPHefG2DsRXjvY6mogEgGbyFYCZ8cAVzfj7wItYtGUfA8fOJXP/Ma9jiUgAqOQrkJs6JPPanZ3YefAEN4yZy4rMg15HEpFyppKvYLqlJvD+z7oRExnBLf+ax7/XZHkdSUTKkUq+Ampepxof3tuN1KQ4Rk5MZ9K8LV5HEpFyopKvoJKqVeKdu7tweYsk/t/Hq/jT52soKNApliLhRiVfgVWJieJfQ9MY1rUxL83axH1vLeFErnaxFAknKvkKLjLCePy61vz2mpZ8sXIXQ8bNZ++Rk17HEhE/UckLZsaIHhfw4q3tWbXjEDe+OJfNe456HUtE/EAlLz/o26Yeb43qwuETedw4Zg4LN+/zOpKIlJFKXv5L+0Y1+fCebtSsEsOQcfOZOG+L9rwRCWEqefmRxrWr8uG93enVPJHHPl7Fw+8u1xuyIiGqVCVvZn3NbJ2ZZZjZo6d5vJGZTTez78xsuZn1939UCaT4ytGMuz2NB69oxvtLMrlZWyGIhKSzlryZRQIvAP2AVsBgM2tVbNhvgcnOuUuAQcAYfweVwIuIMB68ojnjh6Wxde8xfvLP2czeoIuQiISS0szkOwEZzrlNzrkc4G1gQLExDqju+zoe2OG/iOK1Pi3rMOW+S0msFsvtExYwduZGrdOLhIjSlHwDYFuR25m++4p6HLjNzDKBz4H7/ZJOgkaThKp8eE93+rWtx1++WMs9byzhyMk8r2OJyFn4643XwcCrzrlkoD8wycx+9LPNbJSZpZtZenZ2tp+eWgKlamwUzw++hN/0b8nUVbu4/oU5bMw+4nUsETmD0pT8dqBhkdvJvvuKGg5MBnDOzQMqAQnFf5Bz7iXnXJpzLi0xMfH8EounzIyRPS/g9eGd2Xc0h+ufn8PXq7WTpUiwKk3JLwKamVkTM4uh8I3VKcXGfA/0ATCzlhSWvKbqYaxbagKf3H8pTRKrMnJiOk9/tY58bXAmEnTOWvLOuTzgPmAqsIbCs2hWmdnvzew637BfACPNbBnwFnCH0ztzYa9BjcpMvrsrAzsk89w3GQx/bREHj+V6HUtEijCvujgtLc2lp6d78tziX8453lz4PY9PWUW9+Mr8a2gHWtarfvZvFJFzZmaLnXNppR2vT7xKmZkZt3ZuzNujunIyL58bxszh46XF37YRES+o5MVvOjSuySf3X0q7BjV44O2lPPHpanLzC7yOJVKhqeTFr5KqVeKNkZ25o1sK42dv5raXF5B9WPvTi3hFJS9+Fx0ZwePXteYfP72IpdsO0O/ZWUxft9vrWCIVkkpeys0NlyQz5b5LSYiL5c5XFvH4lFXazVIkwFTyUq4urFuNj+7tzl3dm/Dq3C1c9/xs1uw85HUskQpDJS/lrlJ0JI/9pBWv3dWJ/cdyGfD8HF7+dhMF+vCUSLlTyUvA9GqeyJcP9KBn80T+8Nkahr2ykKxDJ7yOJRLWVPISULXjYhl3ewf+eEMbFm3ZR99nZjF11S6vY4mELZW8BNypD099en8PGtSszN2TFvOrD1ZwLEdbF4v4m0pePJOaFMcHP+vO6F5NeXvR91z73GyWZx7wOpZIWFHJi6dioiJ4tF8L3hzRheO5+dw4Zi5jZmRoR0sRP1HJS1Do2rQ2Xz7Qk6tb1+XJL9cxZNx8dhw47nUskZCnkpegEV8lmueHXMLfBl7Eyu0H6fvMLD5ZpssFi5SFSl6Ciplxc4dkPn+gB02T4rj/re94aPJSDp/QPvUi50MlL0Gpce2qvHt3Vx7o04yPvttO/+e+JX3LPq9jiYQclbwErajICH5+ZXPeHd0VgIH/mscTn67meI72vxEpLZW8BL0OjWvx5QM9ua1zY8bP3qxZvcg5UMlLSKgaG8UT17fhzZGdyc0v0KxepJRU8hJSujVNYOqDmtWLlJZKXkLOD7P6Ef+Z1f9Bs3qR01LJS8jqlvqfWf3LmtWLnJZKXkKaZvUiZ6aSl7DQLTWBLx/sya2dG2lWL1KESl7CRlxsFH+4vi1vjuhMTt5/ZvW6rqxUZCp5CTvdUhOY+vMis/pnv2XxVs3qpWJSyUtYKjqrP5lXwM1jNauXikklL2Ht1Kx+SKf/zOrnZuzxOpZIwKjkJezFxUbxxxva8saIzuQWFDDk5QWMnrSYbfuOeR1NpNyp5KXC6J6awNc/78UjV1/IzPXZ9Hl6Jk9NXcvRk7q2rIQvlbxUKJWiI7m3dyrTH76Ma9vW44XpG+n9txl8sCSTAl1yUMKQSl4qpLrxlXj6pxfz/s+6US++Eg9NXsZNY+eydNsBr6OJ+JVKXiq0Do1r8uE93fnbwIvI3H+c61+Ywy8mL2P3oRNeRxPxC5W8VHgREYWXHJz+8GWM7tWUT5btoPffZjBmRoZOuZSQp5IX8YmLjeLRfi346uc96ZaawJNfruOqf8ziq1W7cE7r9RKaVPIixaQkVGXc7WlMGt6J2KgIRk1azNDxC1mfddjraCLnTCUvUoIezRL54oEePP6TVizPPEC/Z7/l/z5eyYFjOV5HEym1UpW8mfU1s3VmlmFmj5Yw5hYzW21mq8zsTf/GFPFGVGQEd3RvwoxHejOkUyMmzd/KZX+bwaR5W8jLL/A6nshZ2dnWGs0sElgPXAlkAouAwc651UXGNAMmA5c75/abWZJzbveZfm5aWppLT08va36RgFq76xC/m7KaeZv20jSxKr/s24KrWtXBzLyOJhWEmS12zqWVdnxpZvKdgAzn3CbnXA7wNjCg2JiRwAvOuf0AZyt4kVDVom513hzZmZeGdgDg7kmLuXnsPO1yKUGrNCXfANhW5Ham776imgPNzWyOmc03s77+CigSbMyMq1rXZeqDPfnTDW35ft8xbnpxHqMmppOx+4jX8UT+i7/eeI0CmgGXAYOBcWZWo/ggMxtlZulmlp6dne2npxbxRlRkBEM6N2LmI5fxiyubM3fjXq5+Zha//nCFPkwlQaM0Jb8daFjkdrLvvqIygSnOuVzn3GYK1/CbFf9BzrmXnHNpzrm0xMTE880sElSqxERxf59mzHjkMm7r3IjJi7bR66kZPP3VOo5o8zPxWGlKfhHQzMyamFkMMAiYUmzMRxTO4jGzBAqXbzb5L6ZI8EuIi+V3A9ow7aFeXN4yiee+yaDXk9OZOG8LuToTRzxy1pJ3zuUB9wFTgTXAZOfcKjP7vZld5xs2FdhrZquB6cAjzrm95RVaJJilJFTlhSHt+fje7jSrE8djH6/iyqdn8tnynfrkrATcWU+hLC86hVIqAuccM9Zl85cv1rIu6zAXNazBr/q1oMsFtb2OJiGqPE6hFJHzZGb0bpHE5w/04Mmb25F18ASDXprP8FcXaZsECQjN5EUC6ERuPhPmbObFGRs5ejKPmzskc//lzWhYq4rX0SREnOtMXiUv4oH9R3N4fnoGk+ZtJd85Blxcn3suSyU1Kc7raBLkVPIiIWTXwROM+3YTbyzYysm8Avq3qcc9vZvSun6819EkSKnkRULQ3iMnmTBnMxPnbuXwyTz6tEji3stTad+optfRJMio5EVC2MHjuUycu4XxczZz4Fgu3VNrc1/vZnS5oJY2QRNAJS8SFo6ezOPNBd/z0rebyD58kg6Na3Lf5alc1jxRZV/BqeRFwsiJ3HzeTd/G2Jmb2H7gOG0aVOe+3qlc1aouEREq+4pIJS8ShnLyCvjou+2MmZHBlr3HaJYUx729U7m2XT2iIvVxl4pEJS8SxvILHJ8u38GY6RtZl3WYxrWr8LNeTbmxfTIxUSr7ikAlL1IBFBQ4vl6TxQvTM1ieeZB68ZW4o1sKgzo1Ir5ytNfxpByp5EUqEOccszbsYeyMjczbtJcqMZHcktaQO7un0Lh2Va/jSTlQyYtUUKt2HGT87M18smwHeQWOK1vWYUSPC+iYUlNn5IQRlbxIBbf70AkmztvK6wu2cuBYLm0bxDOiRxP6t61HtN6kDXkqeREB4HhOPh98l8n42ZvZlH2UutUrMaxbCkM6NSK+itbtQ5VKXkT+S0GBY+b6bF6evYk5GXupHB3JwLRk7uzehCYJWrcPNSp5ESnR6h2HmDBnM1OW7iC3oIA+LeowokcTOjfRtgmhQiUvIme1+/AJXp+3lUnzt7L/WC6t61dnRI8mXNO2vs63D3IqeREptRO5+Xz43XbGz95Mxu4jJFaL5adpDflpx4a6kEmQUsmLyDkrKHDM3JDNpHlbmbFuNw7o2SyRwZ0a0adlks7KCSIqeREpk+0HjjN50TbeWbSNXYdOkFQtlls0uw8aKnkR8Yu8/AJmrMvmrYXfM903u+/RLJEhmt17SiUvIn6348BxJqcXzu53HjxBYrVYbklLZlDHRprdB5hKXkTKTV5+ATPXF87uv1lbdHbfkD4t62h2HwAqeREJiJ0Hj/POov/M7hPiCmf3gztpdl+eVPIiElD5BY6Z63fz5oLC2X2Bgx7NEripfTJXta5DlZgoryOGFZW8iHjm1Oz+vcWZZO4/TtWYSPq3rceN7ZPp3KSWLlnoByp5EfFcQYFj0ZZ9vL8kk89X7OLIyTwa1KjMje0bcGP7ZO2ZUwYqeREJKsdz8vlq9S7eX7Kd2RuyKXDQvlENbmyfzE/a1deOmOdIJS8iQWvXwRN8vHQ77y/JZH3WEWIiI7iiVRI3tU+mZ/NEnZ1TCip5EQl6zjlW7TjEe4szmbJsB/uO5pAQF8N1FzXgxvYNaF2/unbFLIFKXkRCSk5e4bn37y/O5N9rs8jNd1xYpxo3dWjAgIsbUKd6Ja8jBhWVvIiErP1Hc/h0+Q7eX7KdpdsOYAYdG9fimnb16NemLkkqfJW8iISHjdlH+GTZDj5fsZP1WUdU+D4qeREJOxuyDvPZip18tnwnG3b7Cj+lFte0rXiFr5IXkbBW0QtfJS8iFUZFLPxyKXkz6ws8C0QCLzvn/lLCuJuA94COzrkzNrhKXkT86UyF37dN3bA5S8fvJW9mkcB64EogE1gEDHbOrS42rhrwGRAD3KeSFxGvFC98gHbJ8fRpUYcrWiXRql7onodfHiXfFXjcOXe17/avAJxzfy427hnga+AR4GGVvIgEgw1Zh/lqdRbT1mSxdNsBnIP68ZXo07IOV7SqQ5cLahEbFel1zFI715IvzR6gDYBtRW5nAp2LPWl7oKFz7jMze6S0Ty4iUt6a1alGszrVuLd3KtmHTzJ97W6mrcnivcWZTJq/laoxkfRsnkiflnW4vEUStarGeB3Zr8q80bOZRQBPA3eUYuwoYBRAo0aNyvrUIiLnJLFaLLd0bMgtHRtyIjefuRv3MG3Nbv69JosvVu4iwqBD45qFs/yWdWiaWDVkl3VOKfNyjZnFAxuBI75vqQvsA64705KNlmtEJFg451i5/RBfr8li2uosVu88BEBK7Spc4VvWSWtck6gg2ECtPNbkoyh847UPsJ3CN16HOOdWlTB+BlqTF5EQtv3Acb5Zk8W0NbuZt3EvOfkFxFeOpkezBHo2T6RX80TPztbx+5q8cy7PzO4DplJ4CuUE59wqM/s9kO6cm3L+cUVEgk+DGpUZ2jWFoV1TOHIyj9kbsvl69W5mbcjm0+U7AbiwTjV6Ni8s/Y4ptagUHZxv3urDUCIipeScY83Ow8zakM2s9dmkb9lPTn4BlaIj6Nyktm+Wn0DTxLhyW8vXJ15FRALkWE4e8zftZdb6Pcxan82mPUeBwlM0ezZPpGfzRLo3TfDr1a9U8iIiHtm27xjfbigs/DkZezh8Mo8Ig4sb1vih9C9KrkFkGS5orpIXEQkCefkFLN12gFnrs5m5YQ/LMws/iBVfOZr7L09lRI8LzuvnlseHoURE5BxFRUaQllKLtJRaPHTVhew/msPsjMJZfiDPzFHJi4gEQM2qMfzkovr85KL6AX1e78/sFxGRcqOSFxEJYyp5EZEwppIXEQljKnkRkTCmkhcRCWMqeRGRMKaSFxEJY55ta2Bm2cDW8/z2BGCPH+MEgjIHRqhlDrW8oMyBUlLmxs65xNL+EM9KvizMLP1c9m4IBsocGKGWOdTygjIHir8ya7lGRCSMqeRFRMJYqJb8S14HOA/KHBihljnU8oIyB4pfMofkmryIiJROqM7kRUSkFFTyIiJhLKhL3sz6mtk6M8sws0dP83ismb3je3yBmaV4ELNonoZmNt3MVpvZKjN74DRjLjOzg2a21PfnMS+yFsu0xcxW+PL86JqMVug533FebmbtvchZJM+FRY7fUjM7ZGYPFhvj+XE2swlmttvMVha5r5aZfW1mG3x/1yzhe4f5xmwws2Ee5n3KzNb6fu8fmlmNEr73jK+hAGd+3My2F/nd9y/he8/YLwHO/E6RvFvMbGkJ33vux9k5F5R/gEhgI3ABEAMsA1oVG3MPMNb39SDgHY8z1wPa+76uBqw/TebLgE+9Pr7FMm0BEs7weH/gC8CALsACrzMXe53sovADIkF1nIGeQHtgZZH7ngQe9X39KPDX03xfLWCT7++avq9repT3KiDK9/VfT5e3NK+hAGd+HHi4FK+bM/ZLIDMXe/zvwGP+Os7BPJPvBGQ45zY553KAt4EBxcYMAF7zff0e0MfMzv8y6GXknNvpnFvi+/owsAZo4FUePxoATHSF5gM1zKye16F8+gAbnXPn++npcuOcmwXsK3Z30dfsa8D1p/nWq4GvnXP7nHP7ga+BvuWV85TT5XXOfeWcy/PdnA8kl3eOc1HCMS6N0vRLuThTZl9/3QK85a/nC+aSbwBsK3I7kx8X5g9jfC/Eg0DtgKQ7C9/S0SXAgtM83NXMlpnZF2bWOrDJTssBX5nZYjMbdZrHS/O78MogSv4PItiOM0Ad59xO39e7gDqnGROsx/suCv9Fdzpnew0F2n2+JaYJJSyJBesx7gFkOec2lPD4OR/nYC75kGVmccD7wIPOuUPFHl5C4dLCRcA/gY8CHO90LnXOtQf6AfeaWU+vA5WGmcUA1wHvnubhYDzO/8UV/vs7JM5hNrPfAHnAGyUMCabX0ItAU+BiYCeFyx+hYjBnnsWf83EO5pLfDjQscjvZd99px5hZFBAP7A1IuhKYWTSFBf+Gc+6D4o875w455474vv4ciDazhADHLJ5pu+/v3cCHFP5TtqjS/C680A9Y4pzLKv5AMB5nn6xTS12+v3efZkxQHW8zuwO4FrjV9z+mHynFayhgnHNZzrl851wBMK6ELEF1jOGHDrsReKekMedznIO55BcBzcysiW/GNgiYUmzMFODUmQc3A9+U9CIMBN962nhgjXPu6RLG1D31voGZdaLwd+DZ/5jMrKqZVTv1NYVvtK0sNmwKcLvvLJsuwMEiSw5eKnHWE2zHuYiir9lhwMenGTMVuMrMavqWGq7y3RdwZtYX+CVwnXPuWAljSvMaCphi7xfdUEKW0vRLoF0BrHXOZZ7uwfM+zoF4N7kM70L3p/AMlY3Ab3z3/Z7CFxxAJQr/qZ4BLAQu8DjvpRT+83s5sNT3pz8wGhjtG3MfsIrCd/PnA908znyBL8syX65Tx7loZgNe8P0eVgBpQfDaqEphaccXuS+ojjOF/wPaCeRSuOY7nML3jP4NbACmAbV8Y9OAl4t8712+13UGcKeHeTMoXLs+9Xo+dTZbfeDzM72GPMw8yfc6XU5hcdcrntl3+0f94lVm3/2vnnr9Fhlb5uOsbQ1ERMJYMC/XiIhIGankRUTCmEpeRCSMqeRFRMKYSl5EJIyp5EVEwphKXkQkjP1/RPzvVt/N4wUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import seaborn for plotting\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot the training loss over epochs\n",
        "sns.lineplot(x=history.epoch, y=history.history['loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3607ffbf",
      "metadata": {
        "collapsed": true,
        "id": "3607ffbf",
        "outputId": "45ddb972-e092-4878-e338-b7d457918ce9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.034256</td>\n",
              "      <td>0.932957</td>\n",
              "      <td>0.032787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.070273</td>\n",
              "      <td>0.087507</td>\n",
              "      <td>0.842220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.483821</td>\n",
              "      <td>0.293333</td>\n",
              "      <td>0.222846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.016740</td>\n",
              "      <td>0.022930</td>\n",
              "      <td>0.960329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.094652</td>\n",
              "      <td>0.863064</td>\n",
              "      <td>0.042284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.733071</td>\n",
              "      <td>0.089436</td>\n",
              "      <td>0.177493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.591121</td>\n",
              "      <td>0.085639</td>\n",
              "      <td>0.323240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.057439</td>\n",
              "      <td>0.370285</td>\n",
              "      <td>0.572276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.298298</td>\n",
              "      <td>0.521902</td>\n",
              "      <td>0.179801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.060122</td>\n",
              "      <td>0.043421</td>\n",
              "      <td>0.896457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.675752</td>\n",
              "      <td>0.077386</td>\n",
              "      <td>0.246862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.861378</td>\n",
              "      <td>0.019521</td>\n",
              "      <td>0.119101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.029284</td>\n",
              "      <td>0.035787</td>\n",
              "      <td>0.934930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.375218</td>\n",
              "      <td>0.198299</td>\n",
              "      <td>0.426483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.085971</td>\n",
              "      <td>0.802594</td>\n",
              "      <td>0.111435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.123848</td>\n",
              "      <td>0.829425</td>\n",
              "      <td>0.046726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.768745</td>\n",
              "      <td>0.063433</td>\n",
              "      <td>0.167821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.354234</td>\n",
              "      <td>0.158909</td>\n",
              "      <td>0.486857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.141264</td>\n",
              "      <td>0.792196</td>\n",
              "      <td>0.066540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.055609</td>\n",
              "      <td>0.117959</td>\n",
              "      <td>0.826432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.735513</td>\n",
              "      <td>0.151789</td>\n",
              "      <td>0.112699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.567245</td>\n",
              "      <td>0.270691</td>\n",
              "      <td>0.162064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.819221</td>\n",
              "      <td>0.080094</td>\n",
              "      <td>0.100686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.286445</td>\n",
              "      <td>0.549562</td>\n",
              "      <td>0.163993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.553413</td>\n",
              "      <td>0.267001</td>\n",
              "      <td>0.179587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.242511</td>\n",
              "      <td>0.321673</td>\n",
              "      <td>0.435816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.066024</td>\n",
              "      <td>0.884065</td>\n",
              "      <td>0.049912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.052555</td>\n",
              "      <td>0.107742</td>\n",
              "      <td>0.839703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.036527</td>\n",
              "      <td>0.932444</td>\n",
              "      <td>0.031029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.898978</td>\n",
              "      <td>0.023836</td>\n",
              "      <td>0.077186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.238699</td>\n",
              "      <td>0.171374</td>\n",
              "      <td>0.589928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.215132</td>\n",
              "      <td>0.686127</td>\n",
              "      <td>0.098741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.256780</td>\n",
              "      <td>0.162019</td>\n",
              "      <td>0.581201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.161820</td>\n",
              "      <td>0.773835</td>\n",
              "      <td>0.064345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.062587</td>\n",
              "      <td>0.056932</td>\n",
              "      <td>0.880481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.017473</td>\n",
              "      <td>0.930822</td>\n",
              "      <td>0.051704</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2\n",
              "0   0.034256  0.932957  0.032787\n",
              "1   0.070273  0.087507  0.842220\n",
              "2   0.483821  0.293333  0.222846\n",
              "3   0.016740  0.022930  0.960329\n",
              "4   0.094652  0.863064  0.042284\n",
              "5   0.733071  0.089436  0.177493\n",
              "6   0.591121  0.085639  0.323240\n",
              "7   0.057439  0.370285  0.572276\n",
              "8   0.298298  0.521902  0.179801\n",
              "9   0.060122  0.043421  0.896457\n",
              "10  0.675752  0.077386  0.246862\n",
              "11  0.861378  0.019521  0.119101\n",
              "12  0.029284  0.035787  0.934930\n",
              "13  0.375218  0.198299  0.426483\n",
              "14  0.085971  0.802594  0.111435\n",
              "15  0.123848  0.829425  0.046726\n",
              "16  0.768745  0.063433  0.167821\n",
              "17  0.354234  0.158909  0.486857\n",
              "18  0.141264  0.792196  0.066540\n",
              "19  0.055609  0.117959  0.826432\n",
              "20  0.735513  0.151789  0.112699\n",
              "21  0.567245  0.270691  0.162064\n",
              "22  0.819221  0.080094  0.100686\n",
              "23  0.286445  0.549562  0.163993\n",
              "24  0.553413  0.267001  0.179587\n",
              "25  0.242511  0.321673  0.435816\n",
              "26  0.066024  0.884065  0.049912\n",
              "27  0.052555  0.107742  0.839703\n",
              "28  0.036527  0.932444  0.031029\n",
              "29  0.898978  0.023836  0.077186\n",
              "30  0.238699  0.171374  0.589928\n",
              "31  0.215132  0.686127  0.098741\n",
              "32  0.256780  0.162019  0.581201\n",
              "33  0.161820  0.773835  0.064345\n",
              "34  0.062587  0.056932  0.880481\n",
              "35  0.017473  0.930822  0.051704"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Create a DataFrame for the predictions\n",
        "prediction = pd.DataFrame(y_pred, columns=y.columns)\n",
        "\n",
        "# Display the predictions\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "258a4cec",
      "metadata": {
        "collapsed": true,
        "id": "258a4cec",
        "outputId": "8784f4d7-87d1-41de-b653-1fe212ca84dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0     1\n",
              "1     2\n",
              "2     0\n",
              "3     2\n",
              "4     1\n",
              "5     0\n",
              "6     0\n",
              "7     2\n",
              "8     1\n",
              "9     2\n",
              "10    0\n",
              "11    0\n",
              "12    2\n",
              "13    2\n",
              "14    1\n",
              "15    1\n",
              "16    0\n",
              "17    2\n",
              "18    1\n",
              "19    2\n",
              "20    0\n",
              "21    0\n",
              "22    0\n",
              "23    1\n",
              "24    0\n",
              "25    2\n",
              "26    1\n",
              "27    2\n",
              "28    1\n",
              "29    0\n",
              "30    2\n",
              "31    1\n",
              "32    2\n",
              "33    1\n",
              "34    2\n",
              "35    1\n",
              "dtype: int64"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the predicted species by finding the class with the highest probability\n",
        "predicted_species = prediction.idxmax(axis=\"columns\")\n",
        "predicted_species"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11e48ecc",
      "metadata": {
        "collapsed": true,
        "id": "11e48ecc",
        "outputId": "966e33eb-fcf0-4aed-9a95-cfe7922ebfd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[10  0  2]\n",
            " [ 1 12  1]\n",
            " [ 0  0 10]]\n"
          ]
        }
      ],
      "source": [
        "# Import confusion_matrix and accuracy_score for model evaluation\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# Get the true species from the test set\n",
        "true_species = y_test.idxmax(axis=\"columns\")\n",
        "\n",
        "# Compute the confusion matrix\n",
        "matrix = confusion_matrix(true_species, predicted_species)\n",
        "\n",
        "# Display the confusion matrix\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f9cd211",
      "metadata": {
        "collapsed": true,
        "id": "4f9cd211",
        "outputId": "48835fa5-a6c7-4b41-9a24-dcdf20d18ed9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8888888888888888"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate and print the accuracy of the model\n",
        "accuracy_score(true_species, predicted_species)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}